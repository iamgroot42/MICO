{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66af3a1",
   "metadata": {},
   "source": [
    "Start by downloading relevant data from the MICO competition, which can be found [here](https://codalab.lisn.upsaclay.fr/competitions/8551#participate-submit_results) (for CIFAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ef4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from mico_competition.scoring import tpr_at_fpr, score, generate_roc, generate_table\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.distributions import normal\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from mico_competition import ChallengeDataset, load_cifar10, load_model\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch as ch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import tree\n",
    "from scipy.stats import norm\n",
    "\n",
    "import autosklearn.classification\n",
    "import autosklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae0bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_preds(preds):\n",
    "    \"\"\"\n",
    "        Function to normalize given predictions to [0, 1] scale.\n",
    "    \"\"\"\n",
    "    # Normalize to unit interval\n",
    "    min_prediction = np.min(preds)\n",
    "    max_prediction = np.max(preds)\n",
    "    preds = (preds - min_prediction) / (max_prediction - min_prediction)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c510051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_scaled_logits(model, features, labels):\n",
    "    \"\"\"\n",
    "        Use the approach described in LiRA (https://arxiv.org/abs/2112.03570) to use\n",
    "        class-scaled logits instead of direct probabilities.\n",
    "    \"\"\"\n",
    "    outputs = model(features).detach().cpu().numpy()\n",
    "    num_classes = np.arange(outputs.shape[1])\n",
    "    values = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        label = labels[i].item()\n",
    "        wanted = output[label]\n",
    "        not_wanted = output[np.delete(num_classes, label)]\n",
    "        values.append(wanted - np.max(not_wanted))\n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f59183e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def relative_log_merlin(model, features, labels):\n",
    "    \"\"\"\n",
    "        Use the MERLIN (https://arxiv.org/abs/2005.10881) approach to sample neighbors and note\n",
    "        variation in model loss. Modification uses log-scale while noting loss differences.\n",
    "    \"\"\"\n",
    "    epsilon = 0.5\n",
    "    small_value = 1e-10\n",
    "    n_neighbors = 50\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    noise = normal.Normal(0, epsilon)\n",
    "    diffs = []\n",
    "    base_preds = model(features)\n",
    "    base_losses = criterion(base_preds, labels).cpu().numpy()\n",
    "    base_preds = base_preds.cpu().numpy()\n",
    "    for i, feature in enumerate(features):\n",
    "        neighbors = []\n",
    "        distances = []\n",
    "        for _ in range(n_neighbors):\n",
    "            sampled_noise = noise.sample(feature.shape).to(feature.device)\n",
    "            neighbors.append(feature + sampled_noise)\n",
    "            distances.append(sampled_noise.mean().cpu().item())\n",
    "        neighbors = torch.stack(neighbors, 0)\n",
    "        loss_neighbors = criterion(model(neighbors), labels[i].view(1).repeat(n_neighbors))\n",
    "        loss_change = ch.norm((loss_neighbors - base_losses[i])).item()\n",
    "        # Use relative drop instead of absolute\n",
    "        loss_change /= (small_value + base_losses[i].item())\n",
    "        diffs.append(np.log(loss_change + small_value))\n",
    "    diffs = np.array(diffs)\n",
    "    # Clip at zero (lower side)\n",
    "    diffs[diffs < 0] = 0\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d53ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascent_recovery(model, features, labels, adv: bool = False):\n",
    "    \"\"\"\n",
    "        Use gradient-ascent on the given data (and training loss) to make modifications to the input.\n",
    "        Makes note of change in model loss after gradient ascent, as well as the change in the input itself.\n",
    "        Idea: member would have less scope for loss reduction (and consequently smaller changes to the datum itself).\n",
    "    \"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    n_times = 10\n",
    "    step_size = 0.01 if adv else 0.1 # For normal, use higher\n",
    "    final_losses, final_dist = [], []\n",
    "    for i, (feature, label) in enumerate(zip(features, labels)):\n",
    "        model.zero_grad()\n",
    "        feature_var = Variable(feature.clone().detach(), requires_grad=True)\n",
    "        for j in range(n_times):\n",
    "            feature_var = Variable(feature_var.clone().detach(), requires_grad=True)\n",
    "            loss = criterion(model(ch.unsqueeze(feature_var, 0)), torch.unsqueeze(label, 0))\n",
    "            loss.backward(ch.ones_like(loss), retain_graph=True)\n",
    "            with ch.no_grad():\n",
    "                if adv:\n",
    "                    feature_var.data += step_size * feature_var.data\n",
    "                else:\n",
    "                    feature_var.data -= step_size * feature_var.data\n",
    "                loss_new = criterion(model(ch.unsqueeze(feature_var, 0)), ch.unsqueeze(label, 0))\n",
    "        # Get reduction in loss\n",
    "        final_losses.append(loss.item() - loss_new.item())\n",
    "        # Get change in data (norm)\n",
    "        final_dist.append(ch.norm(feature_var.data - feature.data).detach().cpu().numpy())\n",
    "    final_losses = np.stack((final_losses, final_dist), 1)\n",
    "    return final_losses.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00eece15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_epoch(model, features, labels, use_dp: bool = False):\n",
    "    \"\"\"\n",
    "        \"Train\" model on given data to see how much loss changes.\n",
    "        If was with DP, not seen many times (and with clipped gradient), so\n",
    "        expected loss decrease would be much more than that for some point\n",
    "        that has already been seen multiple times. While at it, also take note of gradient norms\n",
    "        P.S I tried using the learning rates corresponding to different training mechanisms,\n",
    "        turns out that using the same, higher LR, works out best in practice.\n",
    "    \"\"\"\n",
    "    # \n",
    "    lr = 0.05 # if use_dp else 0.0005\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    features_collected = []\n",
    "    # Note losses currently\n",
    "    base_preds = model(features).detach()\n",
    "    base_losses = criterion(base_preds, labels).cpu().numpy()\n",
    "    for i, (feature, label) in enumerate(zip(features, labels)):\n",
    "        # Make copy of model\n",
    "        model_ = copy.deepcopy(model)\n",
    "        model_.train()\n",
    "        model_.cuda()\n",
    "        optimizer = ch.optim.SGD(model_.parameters(), lr=lr, momentum=0)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model_(ch.unsqueeze(feature, 0)), ch.unsqueeze(label, 0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Keep track of gradient norms\n",
    "        gradient_norms = [ch.linalg.norm(x.grad.detach().cpu()).item() for x in model_.parameters()]\n",
    "        # Keep track of updated loss\n",
    "        loss_new = criterion(model_(ch.unsqueeze(feature, 0)), ch.unsqueeze(label, 0)).detach().cpu().numpy()\n",
    "        loss_difference = (base_losses[i] - loss_new).item()\n",
    "        gradient_norms += [loss_difference]\n",
    "        features_collected.append(gradient_norms)\n",
    "    features_collected = np.array(features_collected)\n",
    "    features_collected = features_collected.reshape(features_collected.shape[0], -1)\n",
    "    # Do not care about biases or loss diff\n",
    "    features_collected = features_collected[:, [0, 2, 4]]\n",
    "    # features_collected = np.log(features_collected + 1e-10)\n",
    "    return features_collected.reshape(features_collected.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3314852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blind_walk(model, features, labels):\n",
    "    \"\"\"\n",
    "        Inspired by dataset inference (https://arxiv.org/abs/2104.10706)\n",
    "        Take fixed-size steps in random directions (but same random direction)\n",
    "        and keep track of how many steps it takes to flip classification.\n",
    "        Idea: members/non-members would have different proximity to decision boundaries\n",
    "        and thus would have different statistics for this result.\n",
    "    \"\"\"\n",
    "    # Track the number of steps taken until decision flips \n",
    "    # Walk no more than 100 steps, and try 10 different random directions\n",
    "    num_directions = 10\n",
    "    num_max_steps = 100\n",
    "    point_of_failure = np.ones((num_directions, features.shape[0])) * np.inf\n",
    "    std = 0.1\n",
    "    for j in range(num_directions):\n",
    "        noise = ch.randn_like(features) * std\n",
    "        for i in range(1, num_max_steps + 1):\n",
    "            new_labels = ch.argmax(model(features + noise * i).detach(), 1)\n",
    "            flipped = np.nonzero((new_labels != labels).cpu().numpy())[0]\n",
    "            point_of_failure[j][flipped] = np.minimum(point_of_failure[j][flipped], i)\n",
    "    point_of_failure = np.clip(point_of_failure, 0, num_max_steps)\n",
    "    point_of_failure = np.mean(point_of_failure, 0)\n",
    "    return point_of_failure.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2bf0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_feature_collection(model, features, labels, use_dp: bool = False):\n",
    "    \"\"\"\n",
    "        Collect all of the features described above. Also include an 'adv' variant for\n",
    "        gradient-ascent that insted looks to maximize loss instead of minimizing it.\n",
    "    \"\"\"\n",
    "    features_collected = []\n",
    "    features_collected.append(ascent_recovery(model, features, labels))\n",
    "    features_collected.append(ascent_recovery(model, features, labels, adv = True))\n",
    "    features_collected.append(extended_epoch(model, features, labels, use_dp = use_dp))\n",
    "    features_collected.append(relative_log_merlin(model, features, labels).reshape(-1, 1))\n",
    "    features_collected.append(get_class_scaled_logits(model, features, labels).reshape(-1, 1))\n",
    "    features_collected.append(blind_walk(model, features, labels).reshape(-1, 1))\n",
    "    combined_feratures = np.concatenate(features_collected, 1)\n",
    "    return combined_feratures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170d5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matt_modified_scores(model, features, labels, model_reference):\n",
    "    \"\"\"\n",
    "        MATT attack from https://arxiv.org/pdf/1908.11229.pdf\n",
    "        Modified to adapt to the availability of auxiliary models.\n",
    "        Works by comouting gradient alignment between the given model and another reference model.\n",
    "        Idea: given the problem setup, any datapoint is more likely to be a member of a reference model\n",
    "        than not being a member. This attack seeks to utilize this information by\n",
    "        computing these alignment statistics over multiple reference models.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    cos = nn.CosineSimilarity(dim=0)\n",
    "    features_collected = []\n",
    "\n",
    "    # Make copy of model\n",
    "    model_ = copy.deepcopy(model)\n",
    "    model_.cuda()\n",
    "\n",
    "    for i, (feature, label) in enumerate(zip(features, labels)):\n",
    "        # Compute gradients with both models\n",
    "        model_.zero_grad()\n",
    "        model_reference.zero_grad()\n",
    "        loss = criterion(model_(ch.unsqueeze(feature, 0)), ch.unsqueeze(label, 0))\n",
    "        loss_ref = criterion(model_reference(ch.unsqueeze(feature, 0)), ch.unsqueeze(label, 0))\n",
    "        loss.backward()\n",
    "        loss_ref.backward()\n",
    "        \n",
    "        # Compute product\n",
    "        inner_features = []\n",
    "        for p1, p2 in zip(model_.parameters(), model_reference.parameters()):\n",
    "            term = ch.dot(p1.grad.detach().flatten(), p2.grad.detach().flatten()).item()\n",
    "            inner_features.append(term)\n",
    "        features_collected.append(inner_features)\n",
    "    features_collected = np.array(features_collected)\n",
    "    # Focus only on weight-related parameters\n",
    "    features_collected = features_collected[:, [0, 2, 4, 6]]\n",
    "    return features_collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "248c49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_reference_models(reference_features):\n",
    "    num_layers_collected = reference_features.shape[2]\n",
    "    features = []\n",
    "    for i in range(num_layers_collected):\n",
    "        features.append((\n",
    "            np.max(reference_features[:, :, i], 0) - np.min(reference_features[:, :,  i], 0),\n",
    "            np.sum(np.abs(reference_features[:, :,  i]), 0),\n",
    "            np.min(reference_features[:, :,  i], 0),\n",
    "            np.max(reference_features[:, :,  i], 0)\n",
    "        ))\n",
    "    return np.concatenate(features, 0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9afd528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_models():\n",
    "    \"\"\"\n",
    "        Collect all models from the 'train' set\n",
    "    \"\"\"\n",
    "    CHALLENGE = \"cifar10\"\n",
    "    LEN_TRAINING = 50000\n",
    "    LEN_CHALLENGE = 100\n",
    "    scenarios = os.listdir(CHALLENGE)\n",
    "\n",
    "    dataset = load_cifar10(dataset_dir=\"/u/as9rw/work/MICO/data\")\n",
    "\n",
    "    collected_models = {x:[] for x in scenarios}\n",
    "    phase = \"train\"\n",
    "    for scenario in tqdm(scenarios, desc=\"scenario\"):\n",
    "        root = os.path.join(CHALLENGE, scenario, phase)\n",
    "        for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            challenge_dataset = ChallengeDataset.from_path(path, dataset=dataset, len_training=LEN_TRAINING)\n",
    "            challenge_points = challenge_dataset.get_challenges()\n",
    "            \n",
    "            model = load_model('cifar10', path)\n",
    "            collected_models[scenario].append(model)\n",
    "\n",
    "        collected_models[scenario] = np.array(collected_models[scenario], dtype=object)\n",
    "            \n",
    "    return collected_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ceb4d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07acb017b92648b58a8d30291fd0a33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scenario:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7702813cf80c4dad8eb2442dbce5a0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed2e1adf4754c0f88faef9c56be1769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f5c6430a3d411d8af7cc1fdb408927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_models = collect_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b3c98",
   "metadata": {},
   "source": [
    "Feature vectors are a combination of two kinds of features. The first set (originating from `matt_modified_scores`) uses reference models and reference statistics between a given model and these reference models. The second set of features, originating from `custom_feature_collection`, does not use any additional reference models.\n",
    "\n",
    "For Purchase100: without the reference-model-based features, the attack had a maximum TPR@0.1FPR of $\\approx0.13$, and immediately jumped to $0.15$ with the inclusion of those reference-model-based features. Additional experimentation with the meta-classifier itself bumped performance further up to $>0.16$. My experience with these MI attacks has been that the choice of meta-classifier also matters. Most of the MI-related papers I looked at use LR-based models when dealing with features. It thus might be worthwhile to spend some time on feature engineering (using the same set of raw features) and meta-classifier optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26ec6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb89dc8028a4f49a1151144da3b99c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scenario:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec8fb4026b24f1ca1af892d16e969a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863a5df2c4d14e2eb1e5e4719ce0f186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce84b9ac9eff4d02896cd5a6ea8e3edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CHALLENGE = \"cifar10\"\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "phase = \"train\"\n",
    "dataset = load_cifar10(dataset_dir=\"/u/as9rw/work/MICO/data\")\n",
    "LEN_TRAINING = 50000\n",
    "LEN_CHALLENGE = 100\n",
    "\n",
    "X_for_meta, Y_for_meta = {}, {}\n",
    "num_use_others = 25 # 50 worked best, but too slow\n",
    "\n",
    "# Check performance of approach on (1, n-1) models from train\n",
    "for scenario in tqdm(scenarios, desc=\"scenario\"):\n",
    "    use_dp = not scenario.endswith('_inf')\n",
    "    preds_all = []\n",
    "    scores_all = []\n",
    "    root = os.path.join(CHALLENGE, scenario, phase)\n",
    "    all_except = np.arange(100)\n",
    "\n",
    "    for i, model_folder in tqdm(enumerate(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1]))), desc=\"model\", total=100):\n",
    "        path = os.path.join(root, model_folder)\n",
    "        challenge_dataset = ChallengeDataset.from_path(path, dataset=dataset, len_training=LEN_TRAINING)\n",
    "        challenge_points = challenge_dataset.get_challenges()\n",
    "        \n",
    "        challenge_dataloader = torch.utils.data.DataLoader(challenge_points, batch_size=2*LEN_CHALLENGE)\n",
    "        features, labels = next(iter(challenge_dataloader))\n",
    "        features, labels = features.cuda(), labels.cuda()\n",
    "            \n",
    "        model = load_model('cifar10', path)\n",
    "        model.cuda()\n",
    "        features, labels = features.cuda(), labels.cuda()\n",
    "        # Look at all models except this one\n",
    "        other_models = train_models[scenario][np.delete(all_except, i)]\n",
    "        # Pick random models\n",
    "        other_models = np.random.choice(other_models, num_use_others, replace=False)\n",
    "        other_models = [x.cuda() for x in other_models]\n",
    "\n",
    "        features_collected = np.array([matt_modified_scores(model, features, labels, other_model) for other_model in other_models])\n",
    "        scores = extract_features_for_reference_models(features_collected)\n",
    "        other_features = custom_feature_collection(model, features, labels, use_dp = use_dp)\n",
    "        scores = np.concatenate((scores, other_features), 1)\n",
    "\n",
    "        mem_labels = challenge_dataset.get_solutions()\n",
    "\n",
    "        # Store\n",
    "        preds_all.append(mem_labels)\n",
    "        scores_all.append(scores)\n",
    "    \n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    scores_all = np.concatenate(scores_all)\n",
    "    \n",
    "    X_for_meta[scenario] = scores_all\n",
    "    Y_for_meta[scenario] = preds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c032172",
   "metadata": {},
   "source": [
    "Use auto-sklearn (an automl package does does pipeline, optimizer, and hyper-param optimization for you) worked out best, second to using random-forest classifiers. In all scenarios, training classifiers separately for the different scenarios (no, low, high DP) worked better than training a single classifier, even when the scenario is explicitly provided as an input feature (one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cdda6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-01-31 09:30:49,787:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "cifar10_hi AUC (train): 0.59659840625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR_FPR_10</th>\n",
       "      <th>TPR_FPR_100</th>\n",
       "      <th>TPR_FPR_500</th>\n",
       "      <th>TPR_FPR_1000</th>\n",
       "      <th>TPR_FPR_1500</th>\n",
       "      <th>TPR_FPR_2000</th>\n",
       "      <th>AUC</th>\n",
       "      <th>MIA</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.560448</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.54475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPR_FPR_10  TPR_FPR_100  TPR_FPR_500  TPR_FPR_1000  TPR_FPR_1500  \\\n",
       "0         0.0       0.0125        0.061         0.146         0.204   \n",
       "\n",
       "   TPR_FPR_2000       AUC     MIA  accuracy  \n",
       "0         0.257  0.560448  0.0895   0.54475  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-01-31 09:36:36,774:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "cifar10_lo AUC (train): 0.5643315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR_FPR_10</th>\n",
       "      <th>TPR_FPR_100</th>\n",
       "      <th>TPR_FPR_500</th>\n",
       "      <th>TPR_FPR_1000</th>\n",
       "      <th>TPR_FPR_1500</th>\n",
       "      <th>TPR_FPR_2000</th>\n",
       "      <th>AUC</th>\n",
       "      <th>MIA</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.527124</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPR_FPR_10  TPR_FPR_100  TPR_FPR_500  TPR_FPR_1000  TPR_FPR_1500  \\\n",
       "0       0.001       0.0155        0.058         0.106        0.1645   \n",
       "\n",
       "   TPR_FPR_2000       AUC    MIA  accuracy  \n",
       "0        0.2145  0.527124  0.048     0.524  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-01-31 09:39:33,101:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "cifar10_inf AUC (train): 0.6107555\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR_FPR_10</th>\n",
       "      <th>TPR_FPR_100</th>\n",
       "      <th>TPR_FPR_500</th>\n",
       "      <th>TPR_FPR_1000</th>\n",
       "      <th>TPR_FPR_1500</th>\n",
       "      <th>TPR_FPR_2000</th>\n",
       "      <th>AUC</th>\n",
       "      <th>MIA</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.580789</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.5585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPR_FPR_10  TPR_FPR_100  TPR_FPR_500  TPR_FPR_1000  TPR_FPR_1500  \\\n",
       "0      0.0005        0.022        0.087        0.1785        0.2395   \n",
       "\n",
       "   TPR_FPR_2000       AUC    MIA  accuracy  \n",
       "0        0.2975  0.580789  0.117    0.5585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score 0.1435\n"
     ]
    }
   ],
   "source": [
    "# Train different meta-classifiers per scenario\n",
    "CHALLENGE = \"cifar10\"\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "meta_clfs = {x: autosklearn.classification.AutoSklearnClassifier(memory_limit=64 * 1024, time_left_for_this_task=180, metric=autosklearn.metrics.roc_auc) for ii, x in enumerate(X_for_meta.keys())}\n",
    "\n",
    "avg = 0\n",
    "use_all = False\n",
    "for sc in scenarios:\n",
    "    train_split_og, test_split_og = train_test_split(np.arange(100), test_size=20)\n",
    "    train_split = np.concatenate([np.arange(200) + 200 * i for i in train_split_og])\n",
    "    test_split = np.concatenate([np.arange(200) + 200 * i for i in test_split_og])\n",
    "    if use_all:\n",
    "        X_train = X_for_meta[sc]\n",
    "        X_test  = X_for_meta[sc]\n",
    "        y_train = Y_for_meta[sc]\n",
    "        y_test  = Y_for_meta[sc]\n",
    "    else:\n",
    "        X_train = X_for_meta[sc][train_split]\n",
    "        X_test  = X_for_meta[sc][test_split]\n",
    "        y_train = Y_for_meta[sc][train_split]\n",
    "        y_test  = Y_for_meta[sc][test_split]\n",
    "\n",
    "    meta_clfs[sc].fit(X_train, y_train)\n",
    "    preds = meta_clfs[sc].predict_proba(X_test)[:, 1]\n",
    "    preds_train = meta_clfs[sc].predict_proba(X_train)[:, 1]\n",
    "    \n",
    "    print(f\"{sc} AUC (train): {roc_auc_score(y_train, preds_train)}\")\n",
    "    scores = score(y_test, preds)\n",
    "    scores.pop('fpr', None)\n",
    "    scores.pop('tpr', None)\n",
    "    display(pd.DataFrame([scores]))\n",
    "    avg += scores['TPR_FPR_1000']\n",
    "\n",
    "print(\"Average score\", avg / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65e725",
   "metadata": {},
   "source": [
    "For submissions, I set `use_all` to True (since the autoML classifier already does train-val splits internally). The train-test split above is just for visualization purposes (and to see how well the classifier performs on val data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b862d30",
   "metadata": {},
   "source": [
    "## Feature Inspection\n",
    "\n",
    "A closer look (via permutation importance) at the features shows some interesting trends. First,the range of gradient alignment values across reference models seem to be most useful (as opposed to min, max, abs-sum). Features like LiRA and gradient norms in the extended-epoch simulation also seem to be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc0a032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12] range_4   : 0.000 +/- 0.000\n",
      "[23] merlin    : 0.000 +/- 0.000\n",
      "[2] min_1     : 0.000 +/- 0.000\n",
      "[3] max_1     : 0.000 +/- 0.000\n",
      "[19] adv_ascent_diff: 0.000 +/- 0.000\n",
      "[18] adv_ascent_loss: 0.000 +/- 0.000\n",
      "[6] min_2     : 0.000 +/- 0.000\n",
      "[7] max_2     : 0.000 +/- 0.000\n",
      "[17] ascent_diff: 0.000 +/- 0.000\n",
      "[10] min_3     : 0.000 +/- 0.000\n",
      "[11] max_3     : 0.000 +/- 0.000\n",
      "[16] ascent_loss: 0.000 +/- 0.000\n",
      "[14] min_4     : 0.000 +/- 0.000\n",
      "[8] range_3   : 0.004 +/- 0.004\n",
      "[25] blindwalk : 0.005 +/- 0.002\n",
      "[4] range_2   : 0.008 +/- 0.005\n",
      "[20] ext_epo_1 : 0.009 +/- 0.005\n",
      "[1] abssum_1  : 0.011 +/- 0.006\n",
      "[0] range_1   : 0.011 +/- 0.004\n",
      "[15] max_4     : 0.023 +/- 0.006\n",
      "[13] abssum_4  : 0.027 +/- 0.005\n",
      "[24] lira      : 0.029 +/- 0.004\n",
      "[5] abssum_2  : 0.032 +/- 0.008\n",
      "[21] ext_epo_2 : 0.037 +/- 0.005\n",
      "[22] ext_epo_3 : 0.044 +/- 0.005\n",
      "[9] abssum_3  : 0.045 +/- 0.007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import plot_partial_dependence, permutation_importance\n",
    "\n",
    "r = permutation_importance(meta_clfs[\"cifar10_inf\"], X_test, y_test, n_repeats=10, random_state=0)\n",
    "sort_idx = r.importances_mean.argsort()[::-1]\n",
    "\n",
    "labels = []\n",
    "for i in range(4):\n",
    "    labels.append(f\"range_{i+1}\")\n",
    "    labels.append(f\"abssum_{i+1}\")\n",
    "    labels.append(f\"min_{i+1}\")\n",
    "    labels.append(f\"max_{i+1}\")\n",
    "labels.append(\"ascent_loss\")\n",
    "labels.append(\"ascent_diff\")\n",
    "labels.append(\"adv_ascent_loss\")\n",
    "labels.append(\"adv_ascent_diff\")\n",
    "labels.append(\"ext_epo_1\")\n",
    "labels.append(\"ext_epo_2\")\n",
    "labels.append(\"ext_epo_3\")\n",
    "labels.append(\"merlin\")\n",
    "labels.append(\"lira\")\n",
    "labels.append(\"blindwalk\")\n",
    "\n",
    "plt.boxplot(\n",
    "    r.importances[sort_idx].T, labels=[labels[i] for i in sort_idx]\n",
    ")\n",
    "    \n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for i in sort_idx[::-1]:\n",
    "    print(\n",
    "        f\"[{i}] {labels[i]:10s}: {r.importances_mean[i]:.3f} +/- \"\n",
    "        f\"{r.importances_std[i]:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c1d2a",
   "metadata": {},
   "source": [
    "## Collect features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688c422",
   "metadata": {},
   "source": [
    "Collect features for all models across scenarios and phases. Helps to re-use features when experiment with different meta-classifiers. No need to re-run for 'train' models, since we already have features for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGE = \"cifar10\"\n",
    "LEN_TRAINING = 50000\n",
    "LEN_CHALLENGE = 100\n",
    "\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "phases = ['dev', 'final']\n",
    "stored_features = {}\n",
    "\n",
    "dataset = load_cifar10(dataset_dir=\"/u/as9rw/work/MICO/data\")\n",
    "\n",
    "for i, scenario in tqdm(enumerate(scenarios), desc=\"scenario\", total=3):\n",
    "    use_dp = not scenario.endswith('_inf')\n",
    "    stored_features[scenario] = {}\n",
    "    for phase in tqdm(phases, desc=\"phase\"):\n",
    "        stored_features[scenario][phase] = []\n",
    "        root = os.path.join(CHALLENGE, scenario, phase)\n",
    "        all_except = np.arange(100)\n",
    "        for j, model_folder in tqdm(enumerate(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1]))), desc=\"model\", total=len(os.listdir(root))):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            challenge_dataset = ChallengeDataset.from_path(path, dataset=dataset, len_training=LEN_TRAINING)\n",
    "            challenge_points = challenge_dataset.get_challenges()\n",
    "            \n",
    "            model = load_model('cifar10', path)\n",
    "            challenge_dataloader = torch.utils.data.DataLoader(challenge_points, batch_size=2*LEN_CHALLENGE)\n",
    "            features, labels = next(iter(challenge_dataloader))\n",
    "\n",
    "            model.cuda()\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "            # Look at all models except this one\n",
    "            other_models = train_models[scenario][np.delete(all_except, j)]\n",
    "            other_models = np.random.choice(other_models, num_use_others, replace=False)\n",
    "            features_collected = np.array([matt_modified_scores(model, features, labels, other_model.cuda()) for other_model in other_models])\n",
    "            scores = extract_features_for_reference_models(features_collected)\n",
    "            other_features = custom_feature_collection(model, features, labels, use_dp=use_dp)\n",
    "            processed_features = np.concatenate((scores, other_features), 1)\n",
    "\n",
    "            stored_features[scenario][phase].append(processed_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8438600",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2df9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGE = \"cifar10\"\n",
    "LEN_TRAINING = 50000\n",
    "LEN_CHALLENGE = 100\n",
    "\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "phases = ['dev', 'final']\n",
    "\n",
    "dataset = load_cifar10(dataset_dir=\"/u/as9rw/work/MICO/data\")\n",
    "\n",
    "for i, scenario in tqdm(enumerate(scenarios), desc=\"scenario\", total=3):\n",
    "    for phase in tqdm(phases, desc=\"phase\"):\n",
    "        root = os.path.join(CHALLENGE, scenario, phase)\n",
    "        j = 0\n",
    "        for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            features_use = stored_features[scenario][phase][j]\n",
    "            # Using scenario-wise meta-classifier\n",
    "            predictions = meta_clfs[scenario].predict_proba(features_use)[:, 1]\n",
    "            j += 1\n",
    "            assert np.all((0 <= predictions) & (predictions <= 1))\n",
    "\n",
    "            with open(os.path.join(path, \"prediction.csv\"), \"w\") as f:\n",
    "                 csv.writer(f).writerow(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66e1b8",
   "metadata": {},
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f37b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "phases = ['dev', 'final']\n",
    "experiment_name = \"final_submission\"\n",
    "\n",
    "with zipfile.ZipFile(f\"submissions_cifar/{experiment_name}.zip\", 'w') as zipf:\n",
    "    for scenario in tqdm(scenarios, desc=\"scenario\"): \n",
    "        for phase in tqdm(phases, desc=\"phase\"):\n",
    "            root = os.path.join(CHALLENGE, scenario, phase)\n",
    "            for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    zipf.write(file)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}. You need to provide predictions for all challenges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67f1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mico)",
   "language": "python",
   "name": "mico"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
