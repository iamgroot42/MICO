{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Inference Competition (MICO) @ IEEE SatML 2023: Purchase-100\n",
    "\n",
    "Welcome to the MICO competition!\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to one of the challenges.\n",
    "\n",
    "Let's start by downloading and extracting the archive for the Purchase-100 challenge.\n",
    "\n",
    "**NOTE**: Public anonymous access to the competition data is disabled. \n",
    "Upon registering for the competition, you will be shown a URL with an embedded bearer token that you must use instead of the URL below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from mico_competition.scoring import tpr_at_fpr, score, generate_roc, generate_table\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.distributions import normal\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from mico_competition import ChallengeDataset, load_purchase100, load_model\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch as ch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "from mico_competition import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds: ch.Tensor, labels: ch.Tensor) -> float:\n",
    "    return (preds == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module,\n",
    "          train_loader: DataLoader,\n",
    "          criterion,\n",
    "          optimizer: optim.Optimizer,\n",
    "          batch_size: int):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    disable_dp = True\n",
    "    max_physical_batch_size = 128\n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_loader,\n",
    "        max_physical_batch_size=max_physical_batch_size,\n",
    "        optimizer=optimizer\n",
    "    ) as memory_safe_data_loader:\n",
    "\n",
    "        if disable_dp:\n",
    "            data_loader = train_loader\n",
    "        else:\n",
    "            data_loader = memory_safe_data_loader\n",
    "\n",
    "        # BatchSplittingSampler.__len__() approximates (badly) the length in physical batches\n",
    "        # See https://github.com/pytorch/opacus/issues/516\n",
    "        # We instead heuristically keep track of logical batches processed\n",
    "        logical_batch_len = 0\n",
    "        for i, (inputs, target) in enumerate(data_loader):\n",
    "            inputs, target = inputs.cuda(), target.cuda()\n",
    "\n",
    "            logical_batch_len += len(target)\n",
    "            if logical_batch_len >= batch_size:\n",
    "                logical_batch_len = logical_batch_len % max_physical_batch_size\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(loader):\n",
    "    batch_size = 512\n",
    "    learning_rate = 0.001\n",
    "    lr_scheduler_step = 5\n",
    "    lr_scheduler_gamma = 0.9\n",
    "    num_epochs = 30\n",
    "\n",
    "    model = MLP()\n",
    "    model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    sample_rate = 1 / len(loader)\n",
    "    num_steps = int(len(loader) * num_epochs)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_scheduler_step, gamma=lr_scheduler_gamma)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        train(model, loader, criterion, optimizer, batch_size)\n",
    "        scheduler.step()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_preds(preds):\n",
    "    # Normalize to unit interval\n",
    "    min_prediction = np.min(preds)\n",
    "    max_prediction = np.max(preds)\n",
    "    preds = (preds - min_prediction) / (max_prediction - min_prediction)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_losses(model, features, labels):\n",
    "    output = model(features)\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    predictions = -criterion(output, labels).detach().cpu().numpy()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_norm(model, features, labels):\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    features_collected = []\n",
    "    focus = 0\n",
    "    for feature, label in zip(features, labels):\n",
    "        model.zero_grad()\n",
    "        feature_var = Variable(feature)\n",
    "        output = model(feature)\n",
    "        loss = criterion(torch.unsqueeze(output, 0), torch.unsqueeze(label, 0))\n",
    "        loss.backward()\n",
    "        features_collected.append([torch.linalg.norm(x.grad.detach().cpu()).item() for x in model.parameters()])\n",
    "    features_collected = np.array(features_collected)[:, focus]\n",
    "    return features_collected.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascent_recovery(model, features, labels):\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    n_times = 10\n",
    "    step_size = 0.001\n",
    "    final_losses, final_dist = [], []\n",
    "    for i, (feature, label) in enumerate(zip(features, labels)):\n",
    "        model.zero_grad()\n",
    "        feature_var = Variable(feature.clone().detach(), requires_grad=True)\n",
    "        for j in range(n_times):\n",
    "            feature_var = Variable(feature_var.clone().detach(), requires_grad=True)\n",
    "            loss = criterion(torch.unsqueeze(model(feature_var), 0), torch.unsqueeze(label, 0))\n",
    "            loss.backward(ch.ones_like(loss), retain_graph=True)\n",
    "            with ch.no_grad():\n",
    "                feature_var.data -= step_size * feature_var.data\n",
    "                loss_new = criterion(torch.unsqueeze(model(feature_var), 0), torch.unsqueeze(label, 0))\n",
    "        # Get reduction in loss\n",
    "        final_losses.append(loss.item() - loss_new.item())\n",
    "        # Get change in data (norm)\n",
    "        final_dist.append(ch.norm(feature_var.data - feature.data).detach().cpu().numpy())\n",
    "    final_losses = np.array(final_losses)\n",
    "    final_dist = np.array(final_dist)\n",
    "    return np.stack((final_losses, final_dist), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_and_robustness_new(model, features, labels):\n",
    "    features_1 = ascent_recovery(model, features, labels)\n",
    "    features_2 = get_gradient_norm(model, features, labels)\n",
    "    features_3 = get_losses(model, features, labels).reshape(-1, 1)\n",
    "    combined_feratures = np.concatenate((features_1, features_2, features_3), 1)\n",
    "    return combined_feratures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_from_batch(loader):\n",
    "    X, Y = [], []\n",
    "    for batch in loader:\n",
    "        X.append(batch[0])\n",
    "        Y.append(batch[1])\n",
    "    X = ch.cat(X, 0)\n",
    "    Y = ch.cat(Y, 0)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_datasets_generator(data, member, n_times, n_sample):\n",
    "    batch_size = 512\n",
    "    n_workers = 1\n",
    "    for _ in range(n_times):\n",
    "        indices = np.random.choice(len(data[0]), n_sample, replace=False)\n",
    "        dataset_without = TensorDataset(data[0][indices], data[1][indices])\n",
    "        X_wanted = ch.cat((data[0][indices], member[0].view(1, -1)))\n",
    "        Y_wanted = ch.cat((data[1][indices], member[1].view(1)))\n",
    "        dataset = TensorDataset(X_wanted, Y_wanted)\n",
    "        # Make loaders\n",
    "        train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=n_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        train_loader_without = DataLoader(\n",
    "            dataset_without,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=n_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        yield train_loader, train_loader_without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect \"training data\" using models from train split\n",
    "def collect_training_data():\n",
    "    CHALLENGE = \"purchase100\"\n",
    "    LEN_TRAINING = 150000\n",
    "    LEN_CHALLENGE = 100\n",
    "\n",
    "    scenarios = os.listdir(CHALLENGE)\n",
    "\n",
    "    dataset = load_purchase100(dataset_dir=\"/u/as9rw/work/MICO/data\")\n",
    "\n",
    "    collected_features = {x:[] for x in scenarios}\n",
    "    collected_labels = {x:[] for x in scenarios}\n",
    "    phase = \"train\"\n",
    "    for scenario in tqdm(scenarios, desc=\"scenario\"):\n",
    "        root = os.path.join(CHALLENGE, scenario, phase)\n",
    "        for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            challenge_dataset = ChallengeDataset.from_path(path, dataset=dataset, len_training=LEN_TRAINING)\n",
    "            # Get 'rest' data (for shadow-model training)\n",
    "            challenge_points = challenge_dataset.get_rest()\n",
    "            \n",
    "            # Create generator to re-sample data from given data\n",
    "            # Which will then be used for training shadow models\n",
    "            challenge_dataloader = torch.utils.data.DataLoader(challenge_points, batch_size=2*LEN_CHALLENGE)\n",
    "            features, labels = collect_from_batch(challenge_dataloader)\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "            \n",
    "            for feature, label in zip(features, labels):\n",
    "                n_times = 3 #10\n",
    "                n_sample = 1000 #100000\n",
    "                generator = n_datasets_generator((features, labels), (features[0], labels[0]), n_times, n_sample - 1)\n",
    "\n",
    "                X_, Y_ = [], []\n",
    "                for (loader, loader_without) in tqdm(generator, desc=\"Training shadow models\", total=n_times):\n",
    "                    # Train shadow models\n",
    "                    shadow = train_model(loader)\n",
    "                    shadow_without = train_model(loader_without)\n",
    "                \n",
    "                    feature_with = gradient_and_robustness_new(shadow, feature.view(1, -1), label.view(1))\n",
    "                    feature_without = gradient_and_robustness_new(shadow_without, feature.view(1, -1), label.view(1))\n",
    "                    X_.append(feature_with)\n",
    "                    X_.append(feature_without)\n",
    "                    Y_.append(0)\n",
    "                    Y_.append(1)\n",
    "                return X_, Y_\n",
    "            \n",
    "            # Load actual victim model\n",
    "            model = load_model('purchase100', path)\n",
    "            model.cuda()\n",
    "            \n",
    "            # Collect features\n",
    "            collected_features[scenario].append(processed_features)\n",
    "            \n",
    "            # Get labels for membership\n",
    "            collected_labels[scenario].append(challenge_dataset.get_solutions())\n",
    "            np_y = np.array(challenge_dataset.get_solutions())\n",
    "    \n",
    "    for sc in scenarios:\n",
    "        collected_features[sc] = np.concatenate(collected_features[sc], 0)\n",
    "        collected_labels[sc] = np.concatenate(collected_labels[sc], 0)\n",
    "\n",
    "    return collected_features, collected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the Purchase-100 dataset consisting of 197324 records and 600 attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85ba620a79649559fc949164137f72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scenario:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecf3f7a4c6f4d3ba343f5140a8c8870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d16dd410f9149a6ab809a12af1d1917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training shadow models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 171, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 171, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\nRuntimeError: CUDA error: initialization error\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_for_meta, Y_for_meta \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 36\u001b[0m, in \u001b[0;36mcollect_training_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m X_, Y_ \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (loader, loader_without) \u001b[38;5;129;01min\u001b[39;00m tqdm(generator, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining shadow models\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mn_times):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Train shadow models\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     shadow \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     shadow_without \u001b[38;5;241m=\u001b[39m train_model(loader_without)\n\u001b[1;32m     39\u001b[0m     feature_with \u001b[38;5;241m=\u001b[39m gradient_and_robustness_new(shadow, feature\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), label\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     15\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39mlr_scheduler_step, gamma\u001b[38;5;241m=\u001b[39mlr_scheduler_gamma)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# BatchSplittingSampler.__len__() approximates (badly) the length in physical batches\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# See https://github.com/pytorch/opacus/issues/516\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# We instead heuristically keep track of logical batches processed\u001b[39;00m\n\u001b[1;32m     27\u001b[0m logical_batch_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[1;32m     29\u001b[0m     inputs, target \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mcuda(), target\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     31\u001b[0m     logical_batch_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(target)\n",
      "File \u001b[0;32m~/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1199\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1225\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1225\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/mico/lib/python3.8/site-packages/torch/_utils.py:429\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# Some exceptions have first argument as non-str but explicitly\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# have message field\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(message\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[0;32m--> 429\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(msg)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 171, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n  File \"/u/as9rw/anaconda3/envs/mico/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 171, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\nRuntimeError: CUDA error: initialization error\n"
     ]
    }
   ],
   "source": [
    "X_for_meta, Y_for_meta = collect_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGE = \"purchase100\"\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "\n",
    "bins = 100\n",
    "for sc in scenarios:\n",
    "    plt.hist(X_for_meta[sc][Y_for_meta[sc] == 0], bins, alpha=0.5, label='non-members')\n",
    "    plt.hist(X_for_meta[sc][Y_for_meta[sc] == 1], bins, alpha=0.5, label='members')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGE = \"purchase100\"\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "\n",
    "bins = 100\n",
    "for sc in scenarios:\n",
    "    wanted_zero, wanted_one = X_for_meta[sc][Y_for_meta[sc] == 0], X_for_meta[sc][Y_for_meta[sc] == 1]\n",
    "    index = 3\n",
    "    # Layers:\n",
    "    # 4 : 0.57\n",
    "    # 3 : 0.579\n",
    "    # 2 : 0.5733\n",
    "    # 1 : 0.583\n",
    "    plt.scatter(wanted_zero[:, index], wanted_zero[:, 0], label='non-members', s=4, alpha=0.5)\n",
    "    threshold = 10\n",
    "    print((np.mean(wanted_zero[:, index] >= threshold) + np.mean(wanted_one[:, index] <= threshold))/2)\n",
    "    plt.scatter(wanted_one[:, index], wanted_one[:, 0], label='members', s=4, alpha=0.5)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import preprocessing\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Train different meta-classifiers per scenario\n",
    "CHALLENGE = \"purchase100\"\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "meta_clfs = {x: RandomForestClassifier(max_depth=3) for x in X_for_meta.keys()}\n",
    "# meta_clfs = {x: LogisticRegression(n_jobs=-1) for x in X_for_meta.keys()}\n",
    "# meta_clfs = {x: GaussianNB() for x in X_for_meta.keys()}\n",
    "\n",
    "for sc in scenarios:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_for_meta[sc], Y_for_meta[sc], test_size=0.5)\n",
    "    # X_train, X_test = X_train[:, desired], X_test[:, desired]\n",
    "    \n",
    "    meta_clfs[sc].fit(X_train, y_train)\n",
    "    preds = meta_clfs[sc].predict_proba(X_test)[:, 1]\n",
    "    preds_train = meta_clfs[sc].predict_proba(X_train)[:, 1]\n",
    "    \n",
    "    # Round predictions?\n",
    "    preds = np.round(preds, 4)\n",
    "    preds_train = np.round(preds_train, 4)\n",
    "    \n",
    "    print(f\"{sc} AUC (train): {roc_auc_score(y_train, preds_train)}\")\n",
    "    scores = score(y_test, preds)\n",
    "    scores.pop('fpr', None)\n",
    "    scores.pop('tpr', None)\n",
    "    display(pd.DataFrame([scores]))\n",
    "    \n",
    "#     scores = score(y_test, preds)\n",
    "#     fpr = scores['fpr']\n",
    "#     tpr = scores['tpr']\n",
    "    #fig = generate_roc(fpr, tpr)\n",
    "    #fig.suptitle(f\"{sc}\", x=-0.1, y=0.5)\n",
    "    #fig.tight_layout(pad=1.0)\n",
    "    \n",
    "#     result = permutation_importance(meta_clfs[sc], X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "#     forest_importances = pd.Series(result.importances_mean) #, index=feature_names)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "#     ax.set_title(f\"{sc} : Feature importances using permutation\")\n",
    "#     ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use given datapoint, train models w and w/o that point\n",
    "# Adapt KL test (from our SaTML paper) to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another idea- perform one step of GD on model with datapoint, and compare gradient updates with\n",
    "# cases where member was not seen before, and use this as a feature for a meta-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain old permutation-invariant network-based meta-classifier, but also take as input\n",
    "# The raw datapoint. Hope meta-classifier learns to form associations, but not sure how to\n",
    "# design such a meta-classifier (modifications). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_top_k_points(model, data, discard_percentage):\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    dataloader = torch.utils.data.DataLoader(data, batch_size=1000, shuffle=False)\n",
    "    loss_vals = []\n",
    "    for x, y in dataloader:\n",
    "        loss_vals.append(criterion(model(x), y).detach())\n",
    "    loss_vals = ch.cat(loss_vals).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_retraining_attack(model, x, challenge_dataset):\n",
    "    LEN_TRAINING = 150000\n",
    "    LEN_CHALLENGE = 100\n",
    "    rest_points = challenge_dataset.get_rest()\n",
    "    challenge_dataloader = torch.utils.data.DataLoader(rest_points, batch_size=LEN_TRAINING - (2*LEN_CHALLENGE))\n",
    "    rest_x, rest_y = next(iter(challenge_dataloader))\n",
    "    # Get loss values for these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGE = \"purchase100\"\n",
    "LEN_TRAINING = 150000\n",
    "LEN_CHALLENGE = 100\n",
    "\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "phases = ['dev', 'final', 'train']\n",
    "\n",
    "dataset = load_purchase100(dataset_dir=\"/u/as9rw/work/MICO/data\")\n",
    "\n",
    "for scenario in tqdm(scenarios, desc=\"scenario\"):\n",
    "    for phase in tqdm(phases, desc=\"phase\"):\n",
    "        root = os.path.join(CHALLENGE, scenario, phase)\n",
    "        for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            challenge_dataset = ChallengeDataset.from_path(path, dataset=dataset, len_training=LEN_TRAINING)\n",
    "            challenge_points = challenge_dataset.get_challenges()\n",
    "            \n",
    "            model = load_model('purchase100', path)\n",
    "            challenge_dataloader = torch.utils.data.DataLoader(challenge_points, batch_size=2*LEN_CHALLENGE)\n",
    "            features, labels = next(iter(challenge_dataloader))\n",
    "            \n",
    "            # Weighted neighborhood loss fluctuation\n",
    "            # Got score\n",
    "            #predictions = neighborhood_robustness(model, features, labels, 0.2, 20)\n",
    "            #predictions = normalize_preds(predictions)\n",
    "            #predictions = 1 - predictions\n",
    "\n",
    "            # This is where you plug in your membership inference attack\n",
    "            # Combine preds from both\n",
    "            # Got 0.1106 score\n",
    "            # predictions = neighborhood_and_loss(model, features, 0.01, 10)\n",
    "            # predictions = normalize_preds(predictions)\n",
    "            \n",
    "            # Meta-classifier :Random Forest, directly across all data/models\n",
    "            # Got 0.1121 score\n",
    "            # Scenario-wise meta-clfs got 0.1231 score\n",
    "            # processed_features = neighborhood_and_loss(model, features, labels, as_features=True)\n",
    "            \n",
    "            # Meta-classifier: Random forest, on gradient updates\n",
    "            # Got 0.0716 score\n",
    "            # processed_features = get_gradient_norm(model, features, labels)\n",
    "            \n",
    "            # Meta-classifier: Random forest, on gradient updates, loss, and robustness\n",
    "            # Got 0.1224 score\n",
    "            # processed_features = gradient_and_robustness(model, features, labels)\n",
    "            \n",
    "            # Meta-classifier on multiple gradient updates (RF)\n",
    "            # Got 0.1265 score\n",
    "            # processed_features = get_gradient_update_norms(model, features, labels)\n",
    "            \n",
    "            # Meta-classifier on multiple gradient updates, neighborhood loss, and loss\n",
    "            # Got score\n",
    "            # processed_features = get_neighborhood_and_loss(model, features, labels)\n",
    "            \n",
    "            # Meta-classifier on gradient norm (0th), ascent loss diff, and straight-up loss\n",
    "            # Got 0.1342 score\n",
    "            processed_features = gradient_and_robustness_new(model, features, labels)\n",
    "            \n",
    "            predictions = meta_clfs[scenario].predict_proba(processed_features)[:, 1]\n",
    "\n",
    "            assert np.all((0 <= predictions) & (predictions <= 1))\n",
    "\n",
    "            with open(os.path.join(path, \"prediction.csv\"), \"w\") as f:\n",
    "                 csv.writer(f).writerow(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth. \n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR_THRESHOLD = 0.1\n",
    "\n",
    "all_scores = {}\n",
    "phases = ['train']\n",
    "\n",
    "for scenario in tqdm(scenarios, desc=\"scenario\"): \n",
    "    all_scores[scenario] = {}    \n",
    "    for phase in tqdm(phases, desc=\"phase\"):\n",
    "        predictions = []\n",
    "        solutions  = []\n",
    "\n",
    "        root = os.path.join(CHALLENGE, scenario, phase)\n",
    "        for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            predictions.append(np.loadtxt(os.path.join(path, \"prediction.csv\"), delimiter=\",\"))\n",
    "            solutions.append(np.loadtxt(os.path.join(path, \"solution.csv\"),   delimiter=\",\"))\n",
    "\n",
    "        predictions = np.concatenate(predictions)\n",
    "        solutions = np.concatenate(solutions)\n",
    "        \n",
    "        scores = score(solutions, predictions)\n",
    "        all_scores[scenario][phase] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the ROC curve for the attack and see how the attack performed on different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "for scenario in scenarios:\n",
    "    fpr = all_scores[scenario]['train']['fpr']\n",
    "    tpr = all_scores[scenario]['train']['tpr']\n",
    "    fig = generate_roc(fpr, tpr)\n",
    "    fig.suptitle(f\"{scenario}\", x=-0.1, y=0.5)\n",
    "    fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(scenario)\n",
    "    scores = all_scores[scenario]['train']\n",
    "    scores.pop('fpr', None)\n",
    "    scores.pop('tpr', None)\n",
    "    display(pd.DataFrame([scores]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "phases = ['dev', 'final']\n",
    "experiment_name = \"ascent_loss_gradnorm\"\n",
    "\n",
    "with zipfile.ZipFile(f\"{experiment_name}.zip\", 'w') as zipf:\n",
    "    for scenario in tqdm(scenarios, desc=\"scenario\"): \n",
    "        for phase in tqdm(phases, desc=\"phase\"):\n",
    "            root = os.path.join(CHALLENGE, scenario, phase)\n",
    "            for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    zipf.write(file)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}. You need to provide predictions for all challenges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mico)",
   "language": "python",
   "name": "mico"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c823568a0650a753a55947c22141ec594c2fc02bd68b5a71e505ecc57f17796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
